#!/bin/sh
# memU-server è‡ªå®šä¹‰å¯åŠ¨è„šæœ¬
# åœ¨å¯åŠ¨å‰ patch main.pyï¼Œæ³¨å…¥ embed_model é…ç½®

MAIN_PY="/app/app/main.py"
EMBED_MODEL="${DEFAULT_EMBED_MODEL:-nomic-embed-text}"
OLLAMA_URL="${OPENAI_BASE_URL:-http://host.docker.internal:11434/v1}"

# 1. ç­‰å¾… Ollama å¯ç”¨
echo "â³ ç­‰å¾… Ollama ($OLLAMA_URL) å¯ç”¨..."
for i in $(seq 1 30); do
    if python3 -c "
import urllib.request
try:
    r = urllib.request.urlopen('${OLLAMA_URL}/models', timeout=5)
    print('âœ… Ollama å¯ç”¨')
    exit(0)
except Exception as e:
    exit(1)
" 2>/dev/null; then
        break
    fi
    echo "   é‡è¯• $i/30..."
    sleep 2
done

# 2. é¢„çƒ­ embedding æ¨¡å‹
echo "ğŸ”¥ é¢„çƒ­ embedding æ¨¡å‹: $EMBED_MODEL"
python3 -c "
import urllib.request, json
url = '${OLLAMA_URL}/embeddings'
data = json.dumps({'model': '$EMBED_MODEL', 'input': ['warmup']}).encode()
req = urllib.request.Request(url, data=data, headers={'Content-Type': 'application/json'})
try:
    r = urllib.request.urlopen(req, timeout=30)
    print('âœ… é¢„çƒ­å®Œæˆ')
except Exception as e:
    print(f'âš ï¸  é¢„çƒ­å¤±è´¥: {e}')
" 2>&1

# 3. Patch main.py æ³¨å…¥ embed_model
if ! grep -q 'embed_model' "$MAIN_PY"; then
    echo "ğŸ”§ patch memU main.py: æ³¨å…¥ embed_model=$EMBED_MODEL"
    sed -i "/\"model\": os.getenv/a\\            \"embed_model\": \"$EMBED_MODEL\"," "$MAIN_PY"
    echo "   âœ… patch å®Œæˆ"
else
    echo "â„¹ï¸  embed_model å·²å­˜åœ¨ï¼Œè·³è¿‡ patch"
fi

# 4. æ˜¾ç¤º patched çš„ llm_profiles éƒ¨åˆ†
echo "ğŸ“‹ patched main.py llm_profiles:"
grep -A5 'llm_profiles' "$MAIN_PY" | head -10

# 5. å¯åŠ¨ gunicorn (å¢åŠ  timeout åˆ° 120 ç§’ï¼Œç»™ initialize_categories è¶³å¤Ÿæ—¶é—´)
echo "ğŸš€ å¯åŠ¨ gunicorn..."
exec gunicorn app.main:app \
    -k uvicorn.workers.UvicornWorker \
    --bind 0.0.0.0:8000 \
    --timeout 120 \
    --graceful-timeout 30
